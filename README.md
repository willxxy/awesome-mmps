# awesome-mmps
Corpus of resources for multimodal machine learning with physiological signals.

Any additions, corrections, or concerns please submit an issue :). 

***

## Table of Contents

- [Publications and Preprints](#publications-and-preprints)

- [Datasets](#datasets)

- [Laboratories](#laboratories)



## Publications-and-Preprints

- [Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/abstract/document/9395500), IEEE TCDS 2021; [EEG, Eye Movement, Peripheral Physiological Signals, ECG]
- [Multi-view Emotion Recognition Using Deep Canonical Correlation Analysis](https://bcmi.sjtu.edu.cn/~blu/papers/2018/Qiu2018Multi-viewEmotion.pdf), ICONIP 2018; [EEG, Eye Movement]
- [Correlated Attention Networks for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621129), IEEE BIBM 2018; [EEG, Eye Movement]
- [Investigating Sex Differences in Classification of Five Emotions from EEG and Eye Movement Signals](https://drive.google.com/file/d/1pCln0DI3fiIPHHiRiCRcXJWb4LCWskXm/view), IEEE EMBC 2019; [EEG, Eye Movement]
- [Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?](https://arxiv.org/pdf/2301.09017.pdf), EACL Findings 2023; [ECG, Language]
- [An Empirical Exploration of Cross-domain Alignment between Language and Electroencephalogram](https://arxiv.org/pdf/2208.06348.pdf), ICML MLHC Workshop 2023; [EEG, Language]
- [Open Vocabulary Electroencephalography-to-Text Decoding and Zero-Shot Sentiment Classification](https://arxiv.org/abs/2112.02690), AAAI 2022; [EEG, Language]
- [Decoding EEG Brain Activity for Multi-Modal Natural Language Processing](https://www.frontiersin.org/articles/10.3389/fnhum.2021.659410/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Human_Neuroscience&id=659410), Frontiers in Human Neuroscience 2021; [EEG, Eye Movement, Language]
- [Advancing NLP with Cognitive Language Processing Signals](https://arxiv.org/pdf/1904.02682.pdf), arxiv 2019; [EEG, Language, Gaze]
- [Converting ECG Signals to Images for Efficient Image-text Retrieval via Encoding](https://arxiv.org/pdf/2304.06286), arxiv 2023; [ECG, Image, Language]
- [Multimodal Representation Learning of Cardiovascular Magnetic Resonance Imaging](https://arxiv.org/pdf/2304.07675.pdf), arxiv 2023; [CMR, Language]
- [Recognition of emotions using multimodal physiological signals and an ensemble deep learning model](https://www.sciencedirect.com/science/article/pii/S0169260716305090), Computer Methods and Programs in Biomedicine 2017; [EEG, Peripheral Physiological Signals]
- [Multi-modal emotion analysis from facial expressions and electroencephalogram](https://www.sciencedirect.com/science/article/pii/S1077314215002106), Computer Vision and Image Understanding 2016; (EEG, Facial Expressions)
- [An Ensemble Learning Method for Emotion Charting Using Multimodal Physiological Signals](https://www.mdpi.com/1424-8220/22/23/9480), Sensors 2022; [EEG, ECG, GSR]
- [Biometric Recognition Using Multimodal Physiological Signals](https://ieeexplore.ieee.org/document/8740847), IEEE 2019; [Heart Rate, Breathing Rate, Palm Electrodermal Activity, Perinasal Perspitation]
- [Machine-Learning-Based Detection of Craving for Gaming Using Multimodal Physiological Signals: Validation of Test-Retest Reliability for Practical Use](https://www.mdpi.com/1424-8220/19/16/3475), Sensors 2019; [PPG, GSR, EOG]
- [Automated detection of panic disorder based on multimodal physiological signals using machine learning](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2021-0299), ETRI Journal 2022; [ECG, EDA, Respiration, Peripheral Temperature]
- [Video-based multimodal spontaneous emotion recognition using facial expressions and physiological signals](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Ouzar_Video-Based_Multimodal_Spontaneous_Emotion_Recognition_Using_Facial_Expressions_and_Physiological_CVPRW_2022_paper.pdf), CVPR Workshop 2022; [Image, iPPG, Heart Rate]
- [Emotion Recognition from Multimodal Physiological Signals for Emotion Aware Healthcare Systems](https://link.springer.com/article/10.1007/s40846-019-00505-7), Journal of Medical and Biological Engineering 2020; [Respiratory Belt, Photoplethysmography, Fingertip Temperature]
- [A Multimodal Music Recommendation System with Listeners' Personality and Physiological Signals](https://dl.acm.org/doi/abs/10.1145/3383583.3398623), ACM/IEEE JCDL 2020; [Heart Rate, EDA, IBI, Skin Temperature, BVP]
- [Emotion recognition based on multi-modal physiological signals and transfer learning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9493208/), Frontiers in Neuroscience 2022; [EEG, RSP, GSR, Photo-Plethysmograph]
- [Multimodal Affective States Recognition Based on Multiscale CNNs and Biologically Inspired Decision Fusion Model](https://arxiv.org/abs/1911.12918), IEEE Transactions on Affective Computing 2023; [EEG, Peripheral Physiological Signals]

## Datasets
- [SEED](https://bcmi.sjtu.edu.cn/home/seed/seed.html); [EEG, Eye Movement, Video]
- [SEED-IV](https://bcmi.sjtu.edu.cn/home/seed/seed-iv.html); [EEG, Eye Movement, Video]
- [SEED-VIG](https://bcmi.sjtu.edu.cn/home/seed/seed-vig.html); [EEG, EOG]
- [SEED-V](https://bcmi.sjtu.edu.cn/home/seed/seed-v.html); [EEG, Eye Movement, Video]
- [SEED-GER](https://bcmi.sjtu.edu.cn/home/seed/seed-GER.html); [EEG, Eye Movement, Video]
- [SEED-FRA](https://bcmi.sjtu.edu.cn/home/seed/seed-FRA.html); [EEG, Eye Movement, Video]
- [ZuCo 2.0](https://osf.io/2urht/); [EEG, Language, Eye Movement]
- [DEAP](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/); [EEG, Peripheral Physiological Signals, Video]
- [K-EmoCon](https://zenodo.org/record/3762962); [EEG, Peripheral Physiological Signals, Video, Audio]
- [AMIGOS](http://www.eecs.qmul.ac.uk/mmv/datasets/amigos/index.html); [EEG, ECG, GSR, Video]


## Laboratories
- [BCMI Lab @ Shanghai Jiao Tong University](https://bcmi.sjtu.edu.cn/)
- [Centre for Language Technology @ University of Copenhagen](https://cst.ku.dk/english/)
- [Safe AI LAb @ Carnegie Mellon University](https://safeai-lab.github.io/)
- [NeuroMechatronics Lab @ Carnegie Mellon University](https://www.meche.engineering.cmu.edu/faculty/neuromechatronics-lab.html)
- [Interactive Computing Lab @ KAIST](https://ic.kaist.ac.kr/)
- [Laboratory for the Neural Mechanisms of Attention @ UC Davis](https://mangunlab.ucdavis.edu/)
- [HUman Bio-behavioral Signals Lab @ Texas A&M University](https://hubbs.engr.tamu.edu/)
- [Computational Intelligence & Neural Engineering Lab @ Hanyang University](http://cone.hanyang.ac.kr/index_e.html)
- [Bioelectronics Laboratory @ Incheon National University](https://sites.google.com/view/bioelectronics-lab)
  
