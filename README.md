# awesome-mmps
Corpus of resources for multimodal machine learning with physiological signals.

Any additions, corrections, or concerns please submit an issue. For additions to the list, please provide the relevant information. Thank you! :)

***

## Table of Contents

- [Publications and Preprints](#publications-and-preprints)
  - EEG :brain: + X
  - ECG :anatomical_heart: + X
  - EDA :sweat_drops: + X
  - Eye Movement :eye: + X
  - EOG :eye: + X
  - EMG :muscle: + X
  - Other :placard: + X
- [Datasets](#datasets)

- [Laboratories](#laboratories)

- [Citation](#citation)


## Publications-and-Preprints

### EEG :brain: + X 
- [Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/abstract/document/9395500), IEEE TCDS 2021; [EEG, Eye Movement, Peripheral Physiological Signals, ECG]
- [Multi-view Emotion Recognition Using Deep Canonical Correlation Analysis](https://bcmi.sjtu.edu.cn/~blu/papers/2018/Qiu2018Multi-viewEmotion.pdf), ICONIP 2018; [EEG, Eye Movement]
- [Correlated Attention Networks for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621129), IEEE BIBM 2018; [EEG, Eye Movement]
- [Investigating Sex Differences in Classification of Five Emotions from EEG and Eye Movement Signals](https://drive.google.com/file/d/1pCln0DI3fiIPHHiRiCRcXJWb4LCWskXm/view), IEEE EMBC 2019; [EEG, Eye Movement]
- [Can Brain Signals Reveal Inner Alignment with Human Languages?](https://arxiv.org/pdf/2208.06348.pdf), EMNLP Findings 2023; [EEG, Language]
- [Open Vocabulary Electroencephalography-to-Text Decoding and Zero-Shot Sentiment Classification](https://arxiv.org/abs/2112.02690), AAAI 2022; [EEG, Language]
- [Decoding EEG Brain Activity for Multi-Modal Natural Language Processing](https://www.frontiersin.org/articles/10.3389/fnhum.2021.659410/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Human_Neuroscience&id=659410), Frontiers in Human Neuroscience 2021; [EEG, Eye Movement, Language]
- [Advancing NLP with Cognitive Language Processing Signals](https://arxiv.org/pdf/1904.02682.pdf), arxiv 2019; [EEG, Language, Gaze]
- [Recognition of emotions using multimodal physiological signals and an ensemble deep learning model](https://www.sciencedirect.com/science/article/pii/S0169260716305090), Computer Methods and Programs in Biomedicine 2017; [EEG, Peripheral Physiological Signals]
- [Multi-modal emotion analysis from facial expressions and electroencephalogram](https://www.sciencedirect.com/science/article/pii/S1077314215002106), Computer Vision and Image Understanding 2016; (EEG, Facial Expressions)
- [An Ensemble Learning Method for Emotion Charting Using Multimodal Physiological Signals](https://www.mdpi.com/1424-8220/22/23/9480), Sensors 2022; [EEG, ECG, GSR]
- [Emotion recognition based on multi-modal physiological signals and transfer learning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9493208/), Frontiers in Neuroscience 2022; [EEG, RSP, GSR, Photo-Plethysmograph]
- [Multimodal Affective States Recognition Based on Multiscale CNNs and Biologically Inspired Decision Fusion Model](https://arxiv.org/abs/1911.12918), IEEE Transactions on Affective Computing 2023; [EEG, Peripheral Physiological Signals]
- [A Multimodal Approach to Estimating Vigilance Using EEG and Forehead EOG](https://iopscience.iop.org/article/10.1088/1741-2552/aa5a98/pdf), Journal of Neural Engineering 2017; [EEG, EOG]
- [Multimodal Emotion Recognition Using Deep Neural Networks](https://bcmi.sjtu.edu.cn/~liuwei/Wei%20Liu's%20HomePage_files/th_paper_2017.pdf), ICONIP 2017; [EEG, Eye Movement]
- [EmotionMeter: A Multimodal Framework for Recognizing Human Emotions](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8283814), IEEE Transactions on Cybernetics 2019; [EEG, Eye Movement]
- [A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307462), IEEE Transactions on Neural Systems and Rehabilitation Engineering 2018; [EEG, EOG, EMG]
- [Multimodal Adaptive Emotion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels](https://www.semanticscholar.org/paper/Multimodal-Adaptive-Emotion-Transformer-with-Inputs-Jiang-Liu/a08b89ea7269be93bbe0d7f5f8493471b4d1c39c), ACM 2023; [EEG, Eye Movement]
- [Emotion Transformer Fusion: Complementary Representation Properties of EEG and Eye Movements on Recognizing Anger and Surprise](https://bcmi.sjtu.edu.cn/~lubaoliang/papers/2021/2021-14.pdf), IEEE BIBM 2023; [EEG, Eye Movement]
- [Multimodal Physiological Signals Fusion for Online Emotion Recognition](https://dl.acm.org/doi/pdf/10.1145/3581783.3612555), ACM Multimedia 2023; [EEG, ECG, GSR]
- [Graph to Grid: Learning Deep Representations for Multimodal Emotion Recognition](https://dl.acm.org/doi/pdf/10.1145/3581783.3612074), ACM Multimedia 2023; [EEG, Eye Movement, GSR, Respiration, ECG]
- [Stress Classification by Multimodal Physiological Signals Using Variational Mode Decomposition and Machine Learning](https://www.semanticscholar.org/reader/f23f2f2a8bd3f80b44042fd5b58c57c76fcdf281), Hindawi Journal of Healthcare Engineering 2021; [ECG, EEG]
- [Language Mapping using tEEG and EEG Data with Convolutional Neural Networks](https://www.semanticscholar.org/paper/Language-Mapping-using-tEEG-and-EEG-Data-with-Adhikari-Pham/c960eee117d06c20bb5c9a54aedb707a8c277289), IEEE 2022; [EEG, tEEG]
- [Understanding language-elicited EEG data by predicting it from a fine-tuned language model](https://www.semanticscholar.org/paper/Understanding-language-elicited-EEG-data-by-it-from-Schwartz-Mitchell/dacd64e55bea910486289ceac2a5f94217433b79), NAACL 2019; [EEG, ERP, Language]
- [Validation and Interpretation of a Multimodal Drowsiness Detection System Using Explainable Machine Learning](https://www.sciencedirect.com/science/article/pii/S0169260723005916), Computer Methods and Programs in Biomedicine 2023; [EEG, ECG, EOG]
- [A Classification Model for Sensing Human Trust in Machines Using EEG and GSR](https://dl.acm.org/doi/pdf/10.1145/3132743), ACM Transactions on Interactive Intelligent Systems 2018; [EEG, GSR]
- [Evaluating the Stressful Commutes Using Physiological Signals and Machine Learning Techniques](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9990849), IEEE 3ICT 2022; [HR, BP, EEG]
- [Review of Machine and Deep Learning Techniques in Epileptic Seizure Detection using Physiological Signals and Sentiment Analysis](https://dl.acm.org/doi/pdf/10.1145/3552512), ACM 2022; [iEEG, EEG]
- [ECG and EEG based detection and multilevel classification of stress using machine learning for specified genders: A preliminary study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10473514/), PLoS One 2023; [EEG, ECG]
- [Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models](https://proceedings.mlr.press/v209/tang23a.html), CHIL 2023; [EEG, ECG, PSG]
- [Cognitive Load Prediction from Multimodal Physiological Signals using Multiview Learning.](https://www.semanticscholar.org/paper/Cognitive-Load-Prediction-from-Multimodal-Signals-Liu-Yu/5103ff5e420ff93bd37ff414e9789fda99e46424), IEEE journal of biomedical and health informatics 2023; [EEG, EDA, ECG, EOG, & Eye Movements]
- [An Efficient Multimodal Emotion Identification Using FOX Optimized Double Deep Q-Learning](https://dl.acm.org/doi/10.1007/s11277-023-10685-w), Wireless Personal Communications 2023; [GSR, ECG, and EEG]
- [EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer](https://arxiv.org/abs/2405.02165), arxiv 2024; [EEG, Text]
- [Are EEG-to-Text Models Working?](https://arxiv.org/abs/2405.06459), arxiv 2024; [EEG, Text]
- [Aligning Semantic in Brain and Language: A Curriculum Contrastive Method for Electroencephalography-to-Text Generation](https://pubmed.ncbi.nlm.nih.gov/37698960/), IEEE Transactions on Neural Systems and Rehabilitation Engineering 2023, [EEG, Text]
- [A Multitask Framework for Emotion Recognition Using EEG and Eye Movement Signals with Adversarial Training and Attention Mechanism](https://ieeexplore.ieee.org/abstract/document/10385505), IEEE BIBM 2023; [EEG, Eye Movement]
- [Temporal-Spatial Prediction: Pre-Training on Diverse Datasets for EEG Classification](https://ieeexplore.ieee.org/abstract/document/10447845), ICASSP 2024; [EEG]
- [Joint Contrastive Learning with Feature Alignment for Cross-Corpus EEG-based Emotion Recognition](https://arxiv.org/abs/2404.09559), arxiv 2024; [EEG]
- [EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model](https://arxiv.org/abs/2401.10278), arxiv 2024; [EEG]
- [AC-CfC: An attention-based convolutional closed-form continuous-time neural network for raw multi-channel EEG-based emotion recognition](https://www.sciencedirect.com/science/article/pii/S1746809424003070), Biomedical Signal Processing and Control 2024; [EEG]
- [EEG-GPT: Exploring Capabilities of Large Language Models for EEG Classification and Interpretation](https://arxiv.org/abs/2401.18006), arxiv 2024; [EEG, Language]
- [Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI](https://openreview.net/forum?id=QzTpTRVtrP), ICLR 2024; [EEG, Language]
- [Naturalistic Emotion Recognition Using EEG and Eye Movements](https://bcmi.sjtu.edu.cn/home/blu/papers/2023/2023-8.pdf), Springer Nature Singapore 2023; [EEG, Eye Movement]
- [EmotionKD: A Cross-Modal Knowledge Distillation Framework for Emotion Recognition Based on Physiological Signals](https://dl.acm.org/doi/pdf/10.1145/3581783.3612277), ACM 2023; [EEG, GSR]
- [Negative emotion recognition using multimodal physiological signals for advanced driver assistance systems](https://link.springer.com/article/10.1007/s10015-023-00858-y), Artificial Life and Robotics 2023; [ECG, EDA, EEG, and fNIRS]
- [Physiological Fusion Net: Quantifying Individual VR Sickness with Content Stimulus and Physiological Response](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802983), IEEE International Conference on Image Processing (ICIP) 2019; [Vision, EEG, ECG, GSR]
- [DeWave: Discrete EEG Waves Encoding for Brain Dynamics to Text Translation](https://arxiv.org/abs/2309.14030), Neurips 2023; [EEG, Language]
- [DreamDiffusion: Generating High-Quality Images from Brain EEG Signals](https://arxiv.org/pdf/2306.16934.pdf), arxiv 2023; [EEG, Vision]
- [Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography](https://arxiv.org/abs/2311.07868), IEEE BCI 2023; [EEG, EOG, Chin EMG, Event Makers]
- [Multimodal Physiological Signal Emotion Recognition Based on Convolutional Recurrent Neural Network](https://iopscience.iop.org/article/10.1088/1757-899X/782/3/032005), IOP 2020; [EOG, EMG, GSR, RSP, BVP, TMP, EEG]
- [Comparative analysis of physiological signals and electroencephalogram (EEG) for multimodal emotion recognition using generative models](https://ieeexplore.ieee.org/abstract/document/7010181), IEEE STSIVA 2014; [EEG, EOG, EMG, GSR, HR]
- [Large Language Models for Time Series: A Survey](https://arxiv.org/pdf/2402.01801.pdf), arxiv 2024; [EEG, ECG, Text, Vision]
- [An Exploratory Study of Multimodal Physiological Data in Jazz Improvisation Using Basic Machine Learning Techniques](https://arxiv.org/ftp/arxiv/papers/2401/2401.12266.pdf), arxiv 2024; [EDA, EEG]
- [Multimodal Multi-View Spectral-Spatial-Temporal Masked Autoencoder for Self-Supervised Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447194), ICASSP 2024; [EEG, Eye Movement]
- [Functional Emotion Transformer for EEG-Assisted Cross-Modal Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446937), ICASSP 2024; [EEG, Eye Movement]
- [EEG-Transformer: Self-attention from transformer architecture for decoding EEG of imagined speech](https://ieeexplore.ieee.org/abstract/document/9735124), IEEE BCI 2022; [EEG, Speech]
- [Towards Voice Reconstruction from EEG during Imagined Speech](https://ojs.aaai.org/index.php/AAAI/article/view/25745), AAAI 2023; [EEG, Speech]
- [Toward Fully-End-to-End Listened Speech Decoding from EEG Signals](https://arxiv.org/abs/2406.08644), InterSpeech 2024; [EEG, Speech]
- [Enhancing Affective Representations Of Music-Induced Eeg Through Multimodal Supervision And Latent Domain Adaptation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746643), ICASSP 2022; [EEG, Audio]
- [Scaling Law in Neural Data: Non-Invasive Speech Decoding with 175 Hours of EEG Data](https://arxiv.org/abs/2407.07595), arxiv 2024; [EEG, Speech]
- [Hypercomplex Multimodal Emotion Recognition from EEG and Peripheral Physiological Signals](https://arxiv.org/abs/2310.07648), IEEE ICASSP Workshops 2023; [EEG, ECG, GSR]
- [EEG-Based Multimodal Emotion Recognition: A Machine Learning Perspective](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10443946), IEEE Transactions on Instrumentation and Measurement 2024; [EEG, ECG, EMG]
- [SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals](https://raw.githubusercontent.com/mlresearch/v235/main/assets/thapa24a/thapa24a.pdf), ICML 2024; [ECG, EEG, EOG, EMG, Respiratory Sensors]
- [A generative foundation model for five-class sleep staging with arbitrary sensor input](https://www.arxiv.org/abs/2408.15253), arxiv 2024; [EEG, EOG, EMG]
- [NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals](https://arxiv.org/abs/2409.00101), arxiv 2024; [EEG, Text]
- [Explainable Artificial Intelligence on Biosignals for Clinical Decision Support](https://dl.acm.org/doi/pdf/10.1145/3637528.3671459), KDD 2024; [EEG, ECG]
- [Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective](https://arxiv.org/pdf/2409.07388), arxiv 2024; [EEG, ECG, Audio, Text, Image]
- [EEG-Language Modeling for Pathology Detection](https://arxiv.org/pdf/2409.07480), arxiv 2024; [EEG, Text]
- [An ASR-based Hybrid Approach for Auditory Attention Decoding](https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9173483&fileOId=9173484), Lund University Publications 2024; [EEG, Audio]
- [SEE: Semantically Aligned EEG-to-Text Translation](https://arxiv.org/pdf/2409.16312), arxiv 2024; [EEG, Text]
- [Neural Speech Tracking in EEG: Integrating Acoustics and Linguistics for Hearing Aid Users](https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9174277&fileOId=9174278), Lund University Publications 2024; [EEG, Audio]
- [LLM-enhanced Multi-teacher Knowledge Distillation for Modality-Incomplete Emotion Recognition in Daily Healthcare](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10697478), IEEE Journal of Biomedical and Health Informatics 2024; [EEG, GSR]
- [Nested Deep Learning Model Towards A Foundation Model for Brain Signal Data](https://arxiv.org/abs/2410.03191), arxiv 2024; [EEG, MEG]
- [EEG Emotion Copilot: Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation](https://arxiv.org/abs/2410.00166), arxiv 2024; [EEG, Text]
- [Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)](https://arxiv.org/pdf/2410.07507), arxiv 2024; [EEG, Text]
- [EEGPT: Unleashing the Potential of EEG Generalist Foundation Model by Autoregressive Pre-training](https://openreview.net/forum?id=wJ6Bx1IYrQ), OpenReview 2024; [EEG, Text]
- [ARIEL: Brain-Computer Interfaces meet Large Language Models for Emotional Support Conversation](https://dl.acm.org/doi/10.1145/3631700.3665193), Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization 2024; [EEG, Text]
- [Promoting cross-modal representations to improve multimodal foundation models for physiological signals](https://arxiv.org/pdf/2410.16424), Medical Foundation Models (AIM-FM) workshop at NeurIPS 2024; [EEG, EMG, EOG, ECG]
- [DPD (DePression Detection) Net: a deep neural network for multimodal depression detection](https://link.springer.com/article/10.1007/s13755-024-00311-9), Health Information Science and Systems 2024; [EEG, Speech]
- [Deep-learning models reveal how context and listener attention shape electrophysiological correlates of speech-to-language transformation](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012537), PLOS Computational Biology 2024; [EEG, Speech]
- [Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement](https://arxiv.org/pdf/2401.14107), arxiv 2024; [EEG, IMU, EMG, EOG, ECG]
- [Position: Addressing Ethical Challenges and Safety Risks in GenAI-Powered Brain-Computer Interfaces](https://www.researchgate.net/profile/Konstantinos-Barmpas-2/publication/385781911_Position_Addressing_Ethical_Challenges_and_Safety_Risks_in_GenAI-Powered_Brain-Computer_Interfaces/links/6735046ca78ba469f060b48a/Position-Addressing-Ethical-Challenges-and-Safety-Risks-in-GenAI-Powered-Brain-Computer-Interfaces.pdf), GenAI for Health Workshop @ NeurIPS 2024; [EEG, Text]
- [A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation](https://ieeexplore.ieee.org/abstract/document/10752384), IEEE Journal of Biomedical and Health Informatics 2024; [EEG, Text]
- [PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals](https://arxiv.org/pdf/2411.00718), IEEE International Conference on Biomedical and Health Informatics 2024; [EEG, EMG, EOG]
- [Decoding text from electroencephalography signals: A novel Hierarchical Gated Recurrent Unit with Masked Residual Attention Mechanism](https://www.sciencedirect.com/science/article/pii/S0952197624017731), Engineering Applications of Artificial Intelligence 2024; [EEG, Text]
- [Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations for Decoding, Encoding, and Modality Conversion](https://arxiv.org/pdf/2411.09723), arxiv 2024; [EEG, fMRI, MEG, Image]
- [A Survey of LLMs on Biosignal Applications](https://d197for5662m48.cloudfront.net/documents/publicationstatus/232019/preprint_pdf/a5e9124b3b3daff3a6e7766c3e57f047.pdf), arxiv 2024; [ECG, PPG, EEG, IMU, Text]

### ECG :anatomical_heart: + X 
- [Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/abstract/document/9395500), IEEE TCDS 2021; [EEG, Eye Movement, Peripheral Physiological Signals, ECG]
- [Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?](https://arxiv.org/pdf/2301.09017.pdf), EACL Findings 2023; [ECG, Language]
- [Converting ECG Signals to Images for Efficient Image-text Retrieval via Encoding](https://arxiv.org/pdf/2304.06286), Machine Learning for Health 2023; [ECG, Image, Language]
- [An Ensemble Learning Method for Emotion Charting Using Multimodal Physiological Signals](https://www.mdpi.com/1424-8220/22/23/9480), Sensors 2022; [EEG, ECG, GSR]
- [Automated detection of panic disorder based on multimodal physiological signals using machine learning](https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2021-0299), ETRI Journal 2022; [ECG, EDA, Respiration, Peripheral Temperature]
- [ECGBERT: Understanding Hidden Language of ECGs with Self-Supervised Representation Learning](https://arxiv.org/abs/2306.06340), arxiv 2023; [ECG, Language]
- [ECG Language Processing (ELP): A new technique to analyze ECG signals](https://www.sciencedirect.com/science/article/pii/S0169260721000341), Computer Methods and Programs in Biomedicine; [ECG, Language]
- [Robust Patient Information Embedding and Retrieval Mechanism for ECG Signals](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9201451), IEEE Access 2020; [ECG, Language]
- [Multimodal Physiological Signals and Machine Learning for Stress Detection by Wearable Devices](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9856558), IEEE MEMEA 2022; [EDA, ECG, PPG]
- [Multimodal Physiological Signals Fusion for Online Emotion Recognition](https://dl.acm.org/doi/pdf/10.1145/3581783.3612555), ACM Multimedia 2023; [EEG, ECG, GSR]
- [Graph to Grid: Learning Deep Representations for Multimodal Emotion Recognition](https://dl.acm.org/doi/pdf/10.1145/3581783.3612074), ACM Multimedia 2023; [EEG, Eye Movement, GSR, Respiration, ECG]
- [Automated detection of panic disorder based on multimodal physiological signals using machine learning](https://onlinelibrary.wiley.com/doi/epdf/10.4218/etrij.2021-0299?src=getftr), ETRI Journal 2023; [ECG, EDA, RESP, PT]
- [Stress Classification by Multimodal Physiological Signals Using Variational Mode Decomposition and Machine Learning](https://www.semanticscholar.org/reader/f23f2f2a8bd3f80b44042fd5b58c57c76fcdf281), Hindawi Journal of Healthcare Engineering 2021; [ECG, EEG]
- [Validation and Interpretation of a Multimodal Drowsiness Detection System Using Explainable Machine Learning](https://www.sciencedirect.com/science/article/pii/S0169260723005916), Computer Methods and Programs in Biomedicine 2023; [EEG, ECG, EOG]
- [A Novel Algorithm for Movement Artifact Removal in ECG Signals Acquired from Wearable Systems Applied to Horses](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4618928/), PLoS One 2015; [ECG, Accelerometer]
- [Automatic stress detection in car drivers based on non-invasive physiological signals using machine learning techniques](https://link.springer.com/article/10.1007/s00521-023-08428-w), Neural Computing and Applications 2023; [ECG, EMG, GSR, Respiration Rate]
- [Hierarchical extreme puzzle learning machine-based emotion recognition using multimodal physiological signals](https://www.sciencedirect.com/science/article/pii/S1746809423000575), Biomedical Signal Processing and Control 2023; [EDA, ECG, TEMP, RESP, EMR]
- [Machine Learning–Enabled Multimodal Fusion of Intra-Atrial and Body Surface Signals in Prediction of Atrial Fibrillation Ablation Outcomes](https://www.ahajournals.org/doi/full/10.1161/CIRCEP.122.010850), Journal of American Heart Association 2022; [ECG, iECG]
- [ECG and EEG based detection and multilevel classification of stress using machine learning for specified genders: A preliminary study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10473514/), PLoS One 2023; [EEG, ECG]
- [Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models](https://proceedings.mlr.press/v209/tang23a.html), CHIL 2023; [EEG, ECG, PSG]
- [Cognitive Load Prediction from Multimodal Physiological Signals using Multiview Learning.](https://www.semanticscholar.org/paper/Cognitive-Load-Prediction-from-Multimodal-Signals-Liu-Yu/5103ff5e420ff93bd37ff414e9789fda99e46424), IEEE journal of biomedical and health informatics 2023; [EEG, EDA, ECG, EOG, & Eye Movements]
- [ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text](https://arxiv.org/abs/2405.19366), arxiv 2024; [ECG, Text]
- [MEIT: Multi-Modal Electrocardiogram Instruction Tuning on Large Language Models for Report Generation](https://arxiv.org/pdf/2403.04945), arxiv 2024; [ECG, Text]
- [An Efficient Multimodal Emotion Identification Using FOX Optimized Double Deep Q-Learning](https://dl.acm.org/doi/10.1007/s11277-023-10685-w), Wireless Personal Communications 2023; [GSR, ECG, and EEG]
- [A Framework for Cognitive Load Recognition Based on Machine Learning and Multimodal Physiological Signals by Wearable Sensors](https://ieeexplore.ieee.org/abstract/document/10348206), IEEE PRML 2023; [ECG, EDA, and PPG]
- [A Household Multimodal Physiological Signals Monitoring System](https://ieeexplore.ieee.org/document/10082658), IEEE 2023; [ECG, lLEMG, rLEMG, pBCG]
- [ECG-QA: A Comprehensive Question Answering Dataset Combined With Electrocardiogram](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0b67349dd16b83b2cf6167fb4e2be50-Abstract-Datasets_and_Benchmarks.html), NeurIPS 2023; [ECG, Text]
- [Multimodal 12-lead ECG data classification using multi-label DenseNet for heart disease detection](https://ieeexplore.ieee.org/document/9943957), IEEE DSIT 2022; [HRV, ECG, EHR]
- [Time Synchronization of Multimodal Physiological Signals through Alignment of Common Signal Types and Its Technical Considerations in Digital Health](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9145353/), J Imaging 2022; [ECG]
- [Single-modal and multi-modal false arrhythmia alarm reduction using attention-based convolutional and recurrent neural networks](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0226990), PLoS One 2024; [PPG, ABP, ECG]
- [Negative emotion recognition using multimodal physiological signals for advanced driver assistance systems](https://link.springer.com/article/10.1007/s10015-023-00858-y), Artificial Life and Robotics 2023; [ECG, EDA, EEG, and fNIRS]
- [Position Paper: What Can Large Language Models Tell Us about Time Series Analysis](https://arxiv.org/pdf/2402.02713.pdf), arxiv 2024, [ECG, Text]
- [Large Language Model-informed ECG Dual Attention Network for Heart Failure Risk Prediction](https://arxiv.org/abs/2403.10581), arxiv 2024; [ECG, Text]
- [Frozen Language Model Helps ECG Zero-Shot Learning](https://arxiv.org/pdf/2303.12311.pdf), MIDL 2023; [ECG, Text]
- [Zero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation](https://proceedings.mlr.press/v225/yu23b/yu23b.pdf), ML4H 2023; [ECG, Text]
- [Physiological Fusion Net: Quantifying Individual VR Sickness with Content Stimulus and Physiological Response](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802983), IEEE International Conference on Image Processing (ICIP) 2019; [Vision, EEG, ECG, GSR]
- [Text-to-ECG: 12-Lead Electrocardiogram Synthesis conditioned on Clinical Text Reports](https://arxiv.org/pdf/2303.09395.pdf), ICASSP 2023; [ECG, Language]
- [Large Language Models for Time Series: A Survey](https://arxiv.org/pdf/2402.01801.pdf), arxiv 2024; [EEG, ECG, Text, Vision]
- [Integrating multimodal information in machine learning for classifying acute myocardial infarction](https://pubmed.ncbi.nlm.nih.gov/36963114/), Physiological Measurement 2023; [ECG, Text]
- [Multimodal explainable artificial intelligence identifies patients with non-ischaemic cardiomyopathy at risk of lethal ventricular arrhythmias](https://pubmed.ncbi.nlm.nih.gov/38937555/), Scientific reports 2024; [MRI, ECG]
- [Multimodal Estimation Of Change Points Of Physiological Arousal During Driving](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10193718), ICASSP 2023; [ECG, EDA, EMG, HR, BVP]
- [Hypercomplex Multimodal Emotion Recognition from EEG and Peripheral Physiological Signals](https://arxiv.org/abs/2310.07648), IEEE ICASSP Workshops 2023; [EEG, ECG, GSR]
- [Deep learning for ECG classification: A comparative study of 1D and 2D representations and multimodal fusion approaches](https://www.sciencedirect.com/science/article/pii/S174680942400199X), Biomedical Signal Processing and Control 2024; [ECG, Image]
- [Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement](https://arxiv.org/pdf/2403.06659), ICML 2024; [ECG ,Text]
- [SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals](https://raw.githubusercontent.com/mlresearch/v235/main/assets/thapa24a/thapa24a.pdf), ICML 2024; [ECG, EEG, EOG, EMG, Respiratory Sensors]
- [ECG Heartbeat Classification Using Multimodal Fusion](https://ieeexplore.ieee.org/abstract/document/9486862), IEEE Access 2021; [ECG, Image]
- [Multimodal ChatGPT-4V for Electrocardiogram Interpretation: Promise and Limitations](https://www.jmir.org/2024/1/e54607/), JMIR 2024; [ECG, Image]
- [Multimodal ECG heartbeat classification method based on a convolutional neural network embedded with FCA](https://www.nature.com/articles/s41598-024-59311-0), Nature Scientific Reports 2024; [ECG, Image]
- [Large-scale Training of Foundation Models for Wearable Biosignals](https://arxiv.org/pdf/2312.05409), ICLR 2024; [PPG, ECG]
- [ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis](https://arxiv.org/pdf/2408.08849), arxiv 2024; [ECG, Text]
- [CardioGPT: An ECG Interpretation Generation Model](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10488393), IEEE Access 2024; [ECG, Text]
- [Harnessing the Power of ChatGPT in Cardiovascular Medicine: Innovations, Challenges, and Future Directions](https://www.preprints.org/manuscript/202408.2015/v1), preprint 2024; [ECG, Text]
- [The potential for large language models to transform cardiovascular medicine](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00151-1/fulltext), The Lancet Digital Health 2024; [ECG, Text]
- [Explainable Artificial Intelligence on Biosignals for Clinical Decision Support](https://dl.acm.org/doi/pdf/10.1145/3637528.3671459), KDD 2024; [EEG, ECG]
- [Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective](https://arxiv.org/pdf/2409.07388), arxiv 2024; [EEG, ECG, Audio, Text, Image]
- [Electrocardiogram Report Generation and Question Answering via Retrieval-Augmented Self-Supervised Modeling](https://arxiv.org/pdf/2409.08788), arxiv 2024; [Text, ECG]
- [Foundation Models for Cardiovascular Disease Detection via BioSignals from Digital Stethoscopes](https://assets-eu.researchsquare.com/files/rs-4732737/v1_covered_5d102066-509a-4c79-a602-32570aadb619.pdf?c=1722816670), Research Square 2024; [PCG, ECG]
- [From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings](https://arxiv.org/pdf/2410.04133), arxiv 2024; [Text, ECG]
- [Electrocardiogram–Language Model for Few-Shot Question Answering with Meta Learning](https://arxiv.org/pdf/2410.14464), arxiv 2024; [Text, ECG]
- [Promoting cross-modal representations to improve multimodal foundation models for physiological signals](https://arxiv.org/pdf/2410.16424), Medical Foundation Models (AIM-FM) workshop at NeurIPS 2024; [EEG, EMG, EOG, ECG]
- [Foundation Models in Electrocardiogram: A Review](https://arxiv.org/pdf/2410.19877), arxiv 2024; [ECG, Text]
- [C-MELT: Contrastive Enhanced Masked Auto-Encoders for ECG-Language Pre-Training](https://arxiv.org/pdf/2410.02131v1), arxiv 2024; [ECG, Text]
- [Let Your Heart Speak in its Mother Tongue: Multilingual Captioning of Cardiac Signals](https://arxiv.org/abs/2103.11011), arxiv 2021, [ECG, Text]
- [Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement](https://arxiv.org/pdf/2401.14107), arxiv 2024; [EEG, IMU, EMG, EOG, ECG]
- [Precision of artificial intelligence in paediatric cardiology multimodal image interpretation](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/B451CE9897CBE67135E50D9DC0CDEA94/S1047951124036035a.pdf/precision_of_artificial_intelligence_in_paediatric_cardiology_multimodal_image_interpretation.pdf), Cambridge University Press 2024; [ECG, Text]
- [A Survey of LLMs on Biosignal Applications](https://d197for5662m48.cloudfront.net/documents/publicationstatus/232019/preprint_pdf/a5e9124b3b3daff3a6e7766c3e57f047.pdf), arxiv 2024; [ECG, PPG, EEG, IMU, Text]
- [HeartBERT: A Self-Supervised ECG Embedding Model for Efficient and Effective Medical Signal Analysis](https://arxiv.org/abs/2411.11896), arxiv 2024; [ECG, Text]
  
### EDA :sweat_drops: + X
- [A Multimodal Music Recommendation System with Listeners' Personality and Physiological Signals](https://dl.acm.org/doi/abs/10.1145/3383583.3398623), ACM/IEEE JCDL 2020; [Heart Rate, EDA, IBI, Skin Temperature, BVP]
- [Stress Detection with Deep Learning Approaches Using Physiological Signals](https://link.springer.com/chapter/10.1007/978-3-030-69963-5_7), IoT Technologies for Healthcare 2020; [EDA, BVP]
- [Multimodal Physiological Signals and Machine Learning for Stress Detection by Wearable Devices](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9856558), IEEE MEMEA 2022; [EDA, ECG, PPG]
- [Automated detection of panic disorder based on multimodal physiological signals using machine learning](https://onlinelibrary.wiley.com/doi/epdf/10.4218/etrij.2021-0299?src=getftr), ETRI Journal 2023; [ECG, EDA, RESP, PT]
- [Transformer-Based Physiological Feature Learning for Multimodal Analysis of Self-Reported Sentiment](https://dl.acm.org/doi/abs/10.1145/3536221.3556576), ICMI 2022; [EDA, BVP, HR, TEMP]
- [Hierarchical extreme puzzle learning machine-based emotion recognition using multimodal physiological signals](https://www.sciencedirect.com/science/article/pii/S1746809423000575), Biomedical Signal Processing and Control 2023; [EDA, ECG, TEMP, RESP, EMR]
- [A Hybrid Deep Learning Emotion Classification System Using Multimodal Data](https://www.mdpi.com/1424-8220/23/23/9333), Sensors 2023; [EDA, IBI, TEMP, Text, Audio]
- [Exploring the Potential of Multimodal Emotion Recognition for Hearing-Impaired Children Using Physiological Signals and Facial Expressions](https://dl.acm.org/doi/pdf/10.1145/3610661.3616240), ICMI Companion 2023; [ST, EDA, BVP, ACC, HR, Vision]
- [Performance Exploration of RNN Variants for Recognizing Daily Life Stress Levels by Using Multimodal Physiological Signals](https://dl.acm.org/doi/pdf/10.1145/3577190.3614159), ICMI 2023; [EDA, ST, ACC, HR]
- [Transformer-based Self-supervised Multimodal Representation Learning for Wearable Emotion Recognition](https://arxiv.org/abs/2303.17611), IEEE Transactions On Affective Computing 2023; [EDA, BVP, TEMP]
- [Cognitive Load Prediction from Multimodal Physiological Signals using Multiview Learning.](https://www.semanticscholar.org/paper/Cognitive-Load-Prediction-from-Multimodal-Signals-Liu-Yu/5103ff5e420ff93bd37ff414e9789fda99e46424), IEEE journal of biomedical and health informatics 2023; [EEG, EDA, ECG, EOG, & Eye Movements]
- [A Framework for Cognitive Load Recognition Based on Machine Learning and Multimodal Physiological Signals by Wearable Sensors](https://ieeexplore.ieee.org/abstract/document/10348206), IEEE PRML 2023; [ECG, EDA, and PPG]
- [Stress appraisal in the workplace and its associations with productivity and mood: Insights from a multimodal machine learning analysis](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0296468), PLoS One 2024; [EDA, ST, BVP, Accelerometer]
- [Effects of Physiological Signals in Different Types of Multimodal Sentiment Estimation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9726810&tag=1), IEEE AC 2023; [Language, EDA, Audio, Vision]
- [Negative emotion recognition using multimodal physiological signals for advanced driver assistance systems](https://link.springer.com/article/10.1007/s10015-023-00858-y), Artificial Life and Robotics 2023; [ECG, EDA, EEG, and fNIRS]
- [An Exploratory Study of Multimodal Physiological Data in Jazz Improvisation Using Basic Machine Learning Techniques](https://arxiv.org/ftp/arxiv/papers/2401/2401.12266.pdf), arxiv 2024; [EDA, EEG]
- [Multimodal Estimation Of Change Points Of Physiological Arousal During Driving](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10193718), ICASSP 2023; [ECG, EDA, EMG, HR, BVP]

### Eye Movement :eye: + X 
- [Investigating Sex Differences in Classification of Five Emotions from EEG and Eye Movement Signals](https://drive.google.com/file/d/1pCln0DI3fiIPHHiRiCRcXJWb4LCWskXm/view), IEEE EMBC 2019; [EEG, Eye Movement]
- [Decoding EEG Brain Activity for Multi-Modal Natural Language Processing](https://www.frontiersin.org/articles/10.3389/fnhum.2021.659410/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Human_Neuroscience&id=659410), Frontiers in Human Neuroscience 2021; [EEG, Eye Movement, Language]
- [Multi-view Emotion Recognition Using Deep Canonical Correlation Analysis](https://bcmi.sjtu.edu.cn/~blu/papers/2018/Qiu2018Multi-viewEmotion.pdf), ICONIP 2018; [EEG, Eye Movement]
- [Correlated Attention Networks for Multimodal Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621129), IEEE BIBM 2018; [EEG, Eye Movement]
- [Multimodal Emotion Recognition Using Deep Neural Networks](https://bcmi.sjtu.edu.cn/~liuwei/Wei%20Liu's%20HomePage_files/th_paper_2017.pdf), ICONIP 2017; [EEG, Eye Movement]
- [EmotionMeter: A Multimodal Framework for Recognizing Human Emotions](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8283814), IEEE Transactions on Cybernetics 2019; [EEG, Eye Movement]
- [Multimodal Adaptive Emotion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels](https://www.semanticscholar.org/paper/Multimodal-Adaptive-Emotion-Transformer-with-Inputs-Jiang-Liu/a08b89ea7269be93bbe0d7f5f8493471b4d1c39c), ACM 2023; [EEG, Eye Movement]
- [Emotion Transformer Fusion: Complementary Representation Properties of EEG and Eye Movements on Recognizing Anger and Surprise](https://bcmi.sjtu.edu.cn/~lubaoliang/papers/2021/2021-14.pdf), IEEE BIBM 2023; [EEG, Eye Movement]
- [Graph to Grid: Learning Deep Representations for Multimodal Emotion Recognition](https://dl.acm.org/doi/pdf/10.1145/3581783.3612074), ACM Multimedia 2023; [EEG, Eye Movement, GSR, Respiration, ECG]
- [Cognitive Load Prediction from Multimodal Physiological Signals using Multiview Learning.](https://www.semanticscholar.org/paper/Cognitive-Load-Prediction-from-Multimodal-Signals-Liu-Yu/5103ff5e420ff93bd37ff414e9789fda99e46424), IEEE journal of biomedical and health informatics 2023; [EEG, EDA, ECG, EOG, & Eye Movements]
- [Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models](https://arxiv.org/abs/2404.19364), arxiv 2024; [fMRI, Eye Movement]
- [A Multitask Framework for Emotion Recognition Using EEG and Eye Movement Signals with Adversarial Training and Attention Mechanism](https://ieeexplore.ieee.org/abstract/document/10385505), IEEE BIBM 2023; [EEG, Eye Movement]
- [Naturalistic Emotion Recognition Using EEG and Eye Movements](https://bcmi.sjtu.edu.cn/home/blu/papers/2023/2023-8.pdf), Springer Nature Singapore 2023; [EEG, Eye Movement]
- [Multimodal Multi-View Spectral-Spatial-Temporal Masked Autoencoder for Self-Supervised Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10447194), ICASSP 2024; [EEG, Eye Movement]
- [Functional Emotion Transformer for EEG-Assisted Cross-Modal Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446937), ICASSP 2024; [EEG, Eye Movement]
- [EEG2Video: Towards Decoding Dynamic Visual Perception from EEG Signals](https://openreview.net/forum?id=RfsfRn9OFd), NeurIPS 2024; [EEG, fMRI, Video, Text]


### EOG :eye: + X 
- [Machine-Learning-Based Detection of Craving for Gaming Using Multimodal Physiological Signals: Validation of Test-Retest Reliability for Practical Use](https://www.mdpi.com/1424-8220/19/16/3475), Sensors 2019; [PPG, GSR, EOG]
- [A Multimodal Approach to Estimating Vigilance Using EEG and Forehead EOG](https://iopscience.iop.org/article/10.1088/1741-2552/aa5a98/pdf), Journal of Neural Engineering 2017; [EEG, EOG]
- [A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307462), IEEE Transactions on Neural Systems and Rehabilitation Engineering 2018; [EEG, EOG, EMG]
- [Validation and Interpretation of a Multimodal Drowsiness Detection System Using Explainable Machine Learning](https://www.sciencedirect.com/science/article/pii/S0169260723005916), Computer Methods and Programs in Biomedicine 2023; [EEG, ECG, EOG]
- [Cognitive Load Prediction from Multimodal Physiological Signals using Multiview Learning.](https://www.semanticscholar.org/paper/Cognitive-Load-Prediction-from-Multimodal-Signals-Liu-Yu/5103ff5e420ff93bd37ff414e9789fda99e46424), IEEE journal of biomedical and health informatics 2023; [EEG, EDA, ECG, EOG, & Eye Movements]
- [Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography](https://arxiv.org/abs/2311.07868), IEEE BCI 2023; [EEG, EOG, Chin EMG, Event Makers]
- [Multimodal Physiological Signal Emotion Recognition Based on Convolutional Recurrent Neural Network](https://iopscience.iop.org/article/10.1088/1757-899X/782/3/032005), IOP 2020; [EOG, EMG, GSR, RSP, BVP, TMP, EEG]
- [Comparative analysis of physiological signals and electroencephalogram (EEG) for multimodal emotion recognition using generative models](https://ieeexplore.ieee.org/abstract/document/7010181), IEEE STSIVA 2014; [EEG, EOG, EMG, GSR, HR]
- [SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals](https://raw.githubusercontent.com/mlresearch/v235/main/assets/thapa24a/thapa24a.pdf), ICML 2024; [ECG, EEG, EOG, EMG, Respiratory Sensors]
- [A generative foundation model for five-class sleep staging with arbitrary sensor input](https://www.arxiv.org/abs/2408.15253), arxiv 2024; [EEG, EOG, EMG]
- [Promoting cross-modal representations to improve multimodal foundation models for physiological signals](https://arxiv.org/pdf/2410.16424), Medical Foundation Models (AIM-FM) workshop at NeurIPS 2024; [EEG, EMG, EOG, ECG]
- [Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement](https://arxiv.org/pdf/2401.14107), arxiv 2024; [EEG, IMU, EMG, EOG, ECG]
- [PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals](https://arxiv.org/pdf/2411.00718), IEEE International Conference on Biomedical and Health Informatics 2024 2024; [EEG, EMG, EOG]

### EMG :muscle: + X
- [A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307462), IEEE Transactions on Neural Systems and Rehabilitation Engineering 2018; [EEG, EOG, EMG]
- [Automatic stress detection in car drivers based on non-invasive physiological signals using machine learning techniques](https://link.springer.com/article/10.1007/s00521-023-08428-w), Neural Computing and Applications 2023; [ECG, EMG, GSR, Respiration Rate]
- [Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography](https://arxiv.org/abs/2311.07868), IEEE BCI 2023; [EEG, EOG, Chin EMG, Event Makers]
- [Multimodal Physiological Signal Emotion Recognition Based on Convolutional Recurrent Neural Network](https://iopscience.iop.org/article/10.1088/1757-899X/782/3/032005), IOP 2020; [EOG, EMG, GSR, RSP, BVP, TMP, EEG]
- [Comparative analysis of physiological signals and electroencephalogram (EEG) for multimodal emotion recognition using generative models](https://ieeexplore.ieee.org/abstract/document/7010181), IEEE STSIVA 2014; [EEG, EOG, EMG, GSR, HR]
- [Multimodal Estimation Of Change Points Of Physiological Arousal During Driving](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10193718), ICASSP 2023; [ECG, EDA, EMG, HR, BVP]
- [SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals](https://raw.githubusercontent.com/mlresearch/v235/main/assets/thapa24a/thapa24a.pdf), ICML 2024; [ECG, EEG, EOG, EMG, Respiratory Sensors]
- [A generative foundation model for five-class sleep staging with arbitrary sensor input](https://www.arxiv.org/abs/2408.15253), arxiv 2024; [EEG, EOG, EMG]
- [Embracing Large Language and Multimodal Models for Prosthetic Technologies](https://arxiv.org/pdf/2403.04974), arxiv 2024; [EMG, Image, Video, Text, Audio]
- [EMG-to-Speech: Direct Generation of Speech From Facial Electromyographic Signals](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8114359), IEEE/ACM Transactions on Audio, Speech, and Language Processing 2024; [EMG, Speech]
- [Promoting cross-modal representations to improve multimodal foundation models for physiological signals](https://arxiv.org/pdf/2410.16424), Medical Foundation Models (AIM-FM) workshop at NeurIPS 2024; [EEG, EMG, EOG, ECG]
- [Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement](https://arxiv.org/pdf/2401.14107), arxiv 2024; [EEG, IMU, EMG, EOG, ECG]
- [PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals](https://arxiv.org/pdf/2411.00718), IEEE International Conference on Biomedical and Health Informatics 2024 2024; [EEG, EMG, EOG]

### Other :placard: + X
- [Multimodal Representation Learning of Cardiovascular Magnetic Resonance Imaging](https://arxiv.org/pdf/2304.07675.pdf), ICML Workshop on Machine Learning for Multimodal Healthcare Data 2023; [CMR, Language]
- [Biometric Recognition Using Multimodal Physiological Signals](https://ieeexplore.ieee.org/document/8740847), IEEE 2019; [Heart Rate, Breathing Rate, Palm Electrodermal Activity, Perinasal Perspitation]
- [Video-based multimodal spontaneous emotion recognition using facial expressions and physiological signals](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Ouzar_Video-Based_Multimodal_Spontaneous_Emotion_Recognition_Using_Facial_Expressions_and_Physiological_CVPRW_2022_paper.pdf), CVPR Workshop 2022; [Image, iPPG, Heart Rate]
- [Emotion Recognition from Multimodal Physiological Signals for Emotion Aware Healthcare Systems](https://link.springer.com/article/10.1007/s40846-019-00505-7), Journal of Medical and Biological Engineering 2020; [Respiratory Belt, Photoplethysmography, Fingertip Temperature]
- [Every word counts: A multilingual analysis of individual human alignment with model attention](https://arxiv.org/abs/2210.04963), AACl 2022; [Eye-Tracking, Language]
- [Early Life Stress Detection Using Physiological Signals and Machine Learning Pipelines](https://www.mdpi.com/2079-7737/12/1/91), Biology 2023; [Heart Rate, GSR]
- [Comparative Analysis of Emotion Classification Based on Facial Expression and Physiological Signals Using Deep Learning](https://www.mdpi.com/2076-3417/12/3/1286), Applied Sciences 2022; [Facial Expressions, HRV]
- [Towards Autonomous Physiological Signal Extraction From Thermal Videos Using Deep Learning](https://dl.acm.org/doi/10.1145/3577190.3614123), ICMI 2023; [HR, Respiration Rate, Temperature]
- [MAD: Multi-Alignment MEG-to-Text Decoding](https://arxiv.org/abs/2406.01512), arxiv 2024; [MEG, Text]
- [BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification](https://arxiv.org/abs/2406.06786), InterSpeech 2024; [Respiratory Sound, Text]
- [Brant: Foundation Model for Intracranial Neural Signal](https://proceedings.neurips.cc/paper_files/paper/2023/hash/535915d26859036410b0533804cee788-Abstract-Conference.html), NeurIPS 2023; [iEEG]
- [BrainBERT: Self-supervised representation learning for intracranial recordings](https://arxiv.org/abs/2302.14367), ICLR 2023; [iEEG]
- [Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark](https://arxiv.org/pdf/2404.16563), arxiv 2024; [Time Series Agnostic]
- [TOTEM: TOkenized T ime Series EMbeddings for General Time Series Analysis](https://arxiv.org/pdf/2402.16412), arxiv 2024; [Time Series Agnostic]
- [SIM-CNN: Self-Supervised Individualized Multimodal Learning for Stress Prediction on Nurses Using Biosignals](https://www.medrxiv.org/content/medrxiv/early/2023/08/28/2023.08.25.23294640.full.pdf), medRxiv 2023; [EDA, HR, ST, Interbeat Interval, BVP, Accelerometer]
- [Interpretation of Intracardiac Electrograms Through Textual Representations](https://arxiv.org/abs/2402.01115), CHIL 2024; [EGM, Language]
- [Multimodal Risk Prediction with Physiological Signals, Medical Images and Clinical Notes](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10246140/), medRxiv 2023; [Vision, Language, EHR]
- [Do Self-Supervised Speech and Language Models Extract Similar Representations as Human Brain?](https://ieeexplore.ieee.org/abstract/document/10446334), ICASSP 2024; [ECoG, Speech, Text]
- [Emotion Recognition From Multimodal Physiological Signals via Discriminative Correlation Fusion With a Temporal Alignment Mechanism](https://pubmed.ncbi.nlm.nih.gov/37862275/), IEEE Transactions on Cybernetics 2023; [CNS, ANS]
- [Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data](https://arxiv.org/abs/2401.06866), CHIL 2024; [Time Series Agnostic]
- [BIOT: Biosignal Transformer for Cross-data Learning in the Wild](https://proceedings.neurips.cc/paper_files/paper/2023/hash/f6b30f3e2dd9cb53bbf2024402d02295-Abstract-Conference.html), Neurips 2023; [Time Series Agnostic]
- [PhysioMTL: Personalizing Physiological Patterns using Optimal Transport Multi-Task Regression](https://proceedings.mlr.press/v174/zhu22a.html), CHIL 2022; [Time Series Agnostic]
- [Transformers in biosignal analysis: A review](https://www.sciencedirect.com/science/article/pii/S1566253524004755), Elsevier Information Fusion 2024; [Time Series Agnostic]
- [Towards a Personal Health Large Language Model](https://arxiv.org/pdf/2406.06474), arxiv 2024; [Time Series Agnostic]
- [Event-Based Contrastive Learning for Medical Time Series](https://arxiv.org/pdf/2312.10308), MLHC 2024; [Time Series Agnostic]
- [PaPaGei: Open Foundation Models for Optical Physiological Signals](https://arxiv.org/abs/2410.20542), arxiv 2024; [PPG]
- [Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data](https://arxiv.org/abs/2411.06735v1), arxiv 2024; [Time Series Agnostic]
- [COCOA: Cross Modality Contrastive Learning for Sensor Data](https://dl.acm.org/doi/abs/10.1145/3550316), Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2022; [Time Series Agnostic]
- [Language Models Still Struggle to Zero-shot Reason about Time Series](https://arxiv.org/pdf/2404.11757), arxiv 2024; [Time Series Agnostic]
- [TimeSeriesExam: A time series understanding exam](https://arxiv.org/pdf/2410.14752), NeurIPS 2024 Time Series in the Age of Large Models Workshop; [Time Series Agnostic]

## Datasets
- [SEED](https://bcmi.sjtu.edu.cn/home/seed/seed.html); [EEG, Eye Movement, Video]
- [SEED-IV](https://bcmi.sjtu.edu.cn/home/seed/seed-iv.html); [EEG, Eye Movement, Video]
- [SEED-VIG](https://bcmi.sjtu.edu.cn/home/seed/seed-vig.html); [EEG, EOG]
- [SEED-V](https://bcmi.sjtu.edu.cn/home/seed/seed-v.html); [EEG, Eye Movement, Video]
- [SEED-GER](https://bcmi.sjtu.edu.cn/home/seed/seed-GER.html); [EEG, Eye Movement, Video]
- [SEED-FRA](https://bcmi.sjtu.edu.cn/home/seed/seed-FRA.html); [EEG, Eye Movement, Video]
- [ZuCo 2.0](https://osf.io/2urht/); [EEG, Language, Eye Movement]
- [DEAP](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/); [EEG, Peripheral Physiological Signals, Video]
- [K-EmoCon](https://zenodo.org/record/3762962); [EEG, Peripheral Physiological Signals, Video, Audio]
- [AMIGOS](http://www.eecs.qmul.ac.uk/mmv/datasets/amigos/index.html); [EEG, ECG, GSR, Video]
- [Multimodal Adaptive Emotion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels](https://www.semanticscholar.org/paper/Multimodal-Adaptive-Emotion-Transformer-with-Inputs-Jiang-Liu/a08b89ea7269be93bbe0d7f5f8493471b4d1c39c); [EEG, Eye Movement]
- [Dataset of Speech Production in intracranial Electroencephalography](https://www.nature.com/articles/s41597-022-01542-9#code-availability); [Intracranial EEG, Language]
- [Temple University Hospital EEG Seizure Corpus](https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml); [EEG, Artifacts]
- [ECG & EEG Stress Features](https://www.kaggle.com/datasets/apithm/ecg-and-eeg-stress-features/); [EEG, ECG]
- [A multi-modal open dataset for mental-disorder analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9018722/); [EEG, Language]
- [Sleep-EDF](https://www.physionet.org/content/sleep-edfx/1.0.0/); [EEG, EOG, Chin EMG, Event Makers]
- [Neurosity EEG Dataset](https://github.com/JeremyNixon/neurosity/tree/main); [EEG]
- [ECG-QA](https://github.com/Jwoo5/ecg-qa); [ECG, Text]
- [A Large and Rich EEG Dataset for Modeling Human Visual Object Recognition](https://www.sciencedirect.com/science/article/pii/S1053811922008758); [EEG, Image]
- [MIMIC-IV-ECG: Diagnostic Electrocardiogram Matched Subset](https://physionet.org/content/mimic-iv-ecg/1.0/); [ECG, EHR, Text]
- [EEG dataset and OpenBMI toolbox for three BCI paradigms: an investigation into BCI illiteracy](https://academic.oup.com/gigascience/article/8/5/giz002/5304369?login=true); [EEG, EMG]
- [EIT-1M: One Million EEG-Image-Text Pairs for Human Visual-textual Recognition and More](https://arxiv.org/abs/2407.01884); [EEG, Image, Text]
- [Alljoined1 - A dataset for EEG-to-Image decoding](https://arxiv.org/pdf/2404.05553); [EEG, Image]
- [MindBigData](https://mindbigdata.com/opendb/visualmnist.html); [EEG, Image]
- [Human EEG recordings for 1,854 concepts presented in rapid serial visual presentation streams](https://pubmed.ncbi.nlm.nih.gov/35013331/); [EEG, Image]
- [EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels](https://arxiv.org/pdf/2406.07151v1); [EEG, Image]
- [The Dutch EEG Speech Register Corpus](https://mirjamernestus.nl/Ernestus/DESRC/Bentum_tenBosch_vandenBosch_Ernestus_DESRC.pdf); [EEG, Audio]
- [EAV: EEG-Audio-Video Dataset for Emotion Recognition in Conversational Contexts](https://www.nature.com/articles/s41597-024-03838-4); [EEG, Audio, Video]
- [IMPRESSION](https://ieeexplore.ieee.org/abstract/document/9597421); [ECG, BVP, GSR, Video, Audio, Eye Gaze]
- [EEVR](https://openreview.net/forum?id=qgzdGyQcDt&noteId=eeMsdS4M2B); [PPG, EDA, Video]


## Laboratories
- [Neural Interfacing Lab @ Maastricht University](https://neuralinterfacinglab.github.io/)
- [BCMI Lab @ Shanghai Jiao Tong University](https://bcmi.sjtu.edu.cn/)
- [Centre for Language Technology @ University of Copenhagen](https://cst.ku.dk/english/)
- [Safe AI Lab @ Carnegie Mellon University](https://safeai-lab.github.io/)
- [NeuroMechatronics Lab @ Carnegie Mellon University](https://www.meche.engineering.cmu.edu/faculty/neuromechatronics-lab.html)
- [Interactive Computing Lab @ KAIST](https://ic.kaist.ac.kr/)
- [Laboratory for the Neural Mechanisms of Attention @ UC Davis](https://mangunlab.ucdavis.edu/)
- [HUman Bio-behavioral Signals Lab @ Texas A&M University](https://hubbs.engr.tamu.edu/)
- [Computational Intelligence & Neural Engineering Lab @ Hanyang University](http://cone.hanyang.ac.kr/index_e.html)
- [Bioelectronics Laboratory @ Incheon National University](https://sites.google.com/view/bioelectronics-lab)
- [Healthy ML @ MIT](https://healthyml.org/people/)
- [Auton Lab @ Carnegie Mellon University](https://autonlab.org/)
- [Biomedical Functional Imaging and Neuroengineering Laboratory @ Carnegie Mellon University](https://www.cmu.edu/bme/helab/)
- [Laboratoire des Systèmes Perceptifs @ École Normale Supérieure](https://lsp.dec.ens.fr/fr)
- [Brain and AI Team @ Meta](https://ai.meta.com/blog/studying-the-brain-to-build-ai-that-processes-language-as-people-do/)
- [Computational Arrhythmia Research Laboratory @ Stanford University](http://web.stanford.edu/group/narayanlab/cgi-bin/wordpress/)
- [Wu Tsai Institute @ Yale University](https://wti.yale.edu/)
- [Shah Lab @ Stanford University](https://shahlab.stanford.edu/)
- [Edward Yoonjae Choi's Lab @ KAIST](https://mp2893.com/index.html)
- [Scalable Health LAbs @ Rice University](http://sh.rice.edu/)
- [Pattern Recognition & Machine Learning Lab @ Korea University](http://pr.korea.ac.kr/)
- [Signal Analysis and Interpretation Lab @ USC](https://sail.usc.edu/)
- [DataLearning Group @ Imperial College London](https://www.imperial.ac.uk/data-science/research/research-themes/datalearning/)
- [Tison Lab @ UCSF](https://tison.ucsf.edu/people-0)
- [Rajpurkar Lab @ Harvard University](https://www.rajpurkarlab.hms.harvard.edu/)
- [Wang Lab @ University of Toronto](https://wanglab.ai/)
- [MAILAB @ Korea University](http://mailab.korea.ac.kr/index.html)
- [Health AI @ Google](https://ai.google/discover/healthai/)
- [Health AI @ Apple](https://machinelearning.apple.com/research?domain=Health)
- [NIAI Lab @ Hanyang University](http://yoonlab.hanyang.ac.kr/people/)
- [Mobile Systems Research Lab @ University of Cambridge](https://mobile-systems.cl.cam.ac.uk/index.html)
- [Aaqib Saeed's Lab @ Eindhoven University of Technology](https://aqibsaeed.github.io/)
- [Multisensory Intelligence Research Group @ MIT](https://www.media.mit.edu/groups/multisensory-intelligence/overview/)
- [Behavioral Data Science Lab @ University of Washington](https://behavioral-data.github.io/)

## Citation
If you found this repository helpful in your research, please cite the following:

```
@software{Han_A_corpus_of_2024,
author = {Han, William},
month = apr,
title = {{A corpus of resources for Multimodal Learning with Physiological Signals}},
url = {https://github.com/willxxy/awesome-mmps},
version = {2.0.4},
year = {2024}
}
```
